{
    "tests/tokenizers_test.py::test_": 0.8927763108261033,
    "tokenizers_test.py::test_": 0.8927763108261033,
    "tokenizers_test.py::test_sentencepiece_model_detokenizer": 0.9791666666666666
}